{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZc4oUlIOydCLC3XVlqwbs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(root=\"data\", train=True,\n",
        "    download=True, transform=ToTensor())\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train=False,\n",
        "    download=True, transform=ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, layers_data: list, num_classes):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.input_size = input_size\n",
        "    for output_size, activation_function in layers_data:\n",
        "      self.layers.append(nn.Linear(input_size, output_size))\n",
        "      input_size = output_size\n",
        "      self.layers.append(activation_function)\n",
        "    self.layers.append(nn.Linear(input_size, num_classes))\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(23)\n",
        "C = 10\n",
        "N,H,W = training_data.data.shape; D = H*W\n",
        "M1, M2 = 512, 512\n",
        "model = NeuralNetwork(D, [(M1, nn.ReLU()), (M2, nn.ReLU())], C)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X); loss = loss_fn(pred, y)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step() # backprop\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"trloss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset); nbatches = len(dataloader)\n",
        "    teloss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X); teloss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    teloss /= nbatches; correct /= size\n",
        "    print(f\"teacc: {(100*correct):>0.1f}%, teloss: {teloss:>8f} \\n\")\n",
        "\n",
        "learning_rate = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "4PCpT6j4VHj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab6f161-d854-4f6b-af58-a2145bf95a2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "trloss: 2.311403  [    0/60000]\n",
            "trloss: 0.584715  [ 6400/60000]\n",
            "trloss: 0.425315  [12800/60000]\n",
            "trloss: 0.523651  [19200/60000]\n",
            "trloss: 0.457378  [25600/60000]\n",
            "trloss: 0.440629  [32000/60000]\n",
            "trloss: 0.386600  [38400/60000]\n",
            "trloss: 0.524252  [44800/60000]\n",
            "trloss: 0.461581  [51200/60000]\n",
            "trloss: 0.496389  [57600/60000]\n",
            "teacc: 84.0%, teloss: 0.429711 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "trloss: 0.265165  [    0/60000]\n",
            "trloss: 0.350779  [ 6400/60000]\n",
            "trloss: 0.286453  [12800/60000]\n",
            "trloss: 0.386790  [19200/60000]\n",
            "trloss: 0.422265  [25600/60000]\n",
            "trloss: 0.377476  [32000/60000]\n",
            "trloss: 0.321750  [38400/60000]\n",
            "trloss: 0.494972  [44800/60000]\n",
            "trloss: 0.361353  [51200/60000]\n",
            "trloss: 0.428331  [57600/60000]\n",
            "teacc: 85.0%, teloss: 0.405380 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "trloss: 0.220827  [    0/60000]\n",
            "trloss: 0.326628  [ 6400/60000]\n",
            "trloss: 0.243786  [12800/60000]\n",
            "trloss: 0.318946  [19200/60000]\n",
            "trloss: 0.421630  [25600/60000]\n",
            "trloss: 0.350051  [32000/60000]\n",
            "trloss: 0.269149  [38400/60000]\n",
            "trloss: 0.438326  [44800/60000]\n",
            "trloss: 0.334680  [51200/60000]\n",
            "trloss: 0.387788  [57600/60000]\n",
            "teacc: 86.4%, teloss: 0.369679 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "trloss: 0.203996  [    0/60000]\n",
            "trloss: 0.275916  [ 6400/60000]\n",
            "trloss: 0.223614  [12800/60000]\n",
            "trloss: 0.253243  [19200/60000]\n",
            "trloss: 0.466210  [25600/60000]\n",
            "trloss: 0.324836  [32000/60000]\n",
            "trloss: 0.250219  [38400/60000]\n",
            "trloss: 0.414612  [44800/60000]\n",
            "trloss: 0.298207  [51200/60000]\n",
            "trloss: 0.360531  [57600/60000]\n",
            "teacc: 86.2%, teloss: 0.376901 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "trloss: 0.207442  [    0/60000]\n",
            "trloss: 0.237929  [ 6400/60000]\n",
            "trloss: 0.216594  [12800/60000]\n",
            "trloss: 0.195145  [19200/60000]\n",
            "trloss: 0.367450  [25600/60000]\n",
            "trloss: 0.326847  [32000/60000]\n",
            "trloss: 0.276795  [38400/60000]\n",
            "trloss: 0.353276  [44800/60000]\n",
            "trloss: 0.290225  [51200/60000]\n",
            "trloss: 0.362011  [57600/60000]\n",
            "teacc: 87.3%, teloss: 0.356489 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "trloss: 0.201030  [    0/60000]\n",
            "trloss: 0.209293  [ 6400/60000]\n",
            "trloss: 0.220657  [12800/60000]\n",
            "trloss: 0.191692  [19200/60000]\n",
            "trloss: 0.380112  [25600/60000]\n",
            "trloss: 0.315457  [32000/60000]\n",
            "trloss: 0.241834  [38400/60000]\n",
            "trloss: 0.321036  [44800/60000]\n",
            "trloss: 0.252075  [51200/60000]\n",
            "trloss: 0.300853  [57600/60000]\n",
            "teacc: 87.2%, teloss: 0.367755 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "trloss: 0.179091  [    0/60000]\n",
            "trloss: 0.216624  [ 6400/60000]\n",
            "trloss: 0.199566  [12800/60000]\n",
            "trloss: 0.220436  [19200/60000]\n",
            "trloss: 0.331400  [25600/60000]\n",
            "trloss: 0.317738  [32000/60000]\n",
            "trloss: 0.219527  [38400/60000]\n",
            "trloss: 0.294608  [44800/60000]\n",
            "trloss: 0.239563  [51200/60000]\n",
            "trloss: 0.333036  [57600/60000]\n",
            "teacc: 87.6%, teloss: 0.366069 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "trloss: 0.188667  [    0/60000]\n",
            "trloss: 0.237158  [ 6400/60000]\n",
            "trloss: 0.191245  [12800/60000]\n",
            "trloss: 0.183715  [19200/60000]\n",
            "trloss: 0.299649  [25600/60000]\n",
            "trloss: 0.245791  [32000/60000]\n",
            "trloss: 0.199186  [38400/60000]\n",
            "trloss: 0.290738  [44800/60000]\n",
            "trloss: 0.243117  [51200/60000]\n",
            "trloss: 0.390982  [57600/60000]\n",
            "teacc: 87.7%, teloss: 0.363174 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "trloss: 0.128343  [    0/60000]\n",
            "trloss: 0.227796  [ 6400/60000]\n",
            "trloss: 0.159525  [12800/60000]\n",
            "trloss: 0.216027  [19200/60000]\n",
            "trloss: 0.281756  [25600/60000]\n",
            "trloss: 0.247695  [32000/60000]\n",
            "trloss: 0.190056  [38400/60000]\n",
            "trloss: 0.238249  [44800/60000]\n",
            "trloss: 0.259509  [51200/60000]\n",
            "trloss: 0.293688  [57600/60000]\n",
            "teacc: 87.5%, teloss: 0.363787 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "trloss: 0.121614  [    0/60000]\n",
            "trloss: 0.194066  [ 6400/60000]\n",
            "trloss: 0.156752  [12800/60000]\n",
            "trloss: 0.145081  [19200/60000]\n",
            "trloss: 0.326025  [25600/60000]\n",
            "trloss: 0.238822  [32000/60000]\n",
            "trloss: 0.161523  [38400/60000]\n",
            "trloss: 0.209458  [44800/60000]\n",
            "trloss: 0.242659  [51200/60000]\n",
            "trloss: 0.270398  [57600/60000]\n",
            "teacc: 87.0%, teloss: 0.404059 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}